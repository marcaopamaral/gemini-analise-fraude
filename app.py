import streamlit as st
import os
import time
import json
import requests
import pandas as pd
from tools import carregar_dados_ou_demo, consulta_tool, grafico_tool # Importa todas as fun√ß√µes de tools
from io import BytesIO

# --- 1. Configura√ß√µes e Constantes ---

MODEL_NAME = "gemini-2.5-flash-preview-05-20"
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent"

# Defini√ß√£o das Ferramentas (mantida)
SYSTEM_INSTRUCTION_TEXT = "Voc√™ √© um Analista de Fraude de Cart√£o de Cr√©dito especializado em pandas. Sua tarefa √© analisar o DataFrame 'df' que cont√©m dados transacionais. As colunas V1-V28 s√£o resultados de PCA. A coluna 'Amount' √© o valor, 'Time' √© o tempo e 'Class' (0=Normal, 1=Fraude) √© o alvo. Use as ferramentas 'consulta_tool' para todas as an√°lises de dados e 'grafico_tool' para visualizar os dados. Retorne apenas o resultado da an√°lise ou a resposta amig√°vel ao usu√°rio. Se o usu√°rio pedir para analisar ou resumir dados, USE A FERRAMENTA. N√ÉO tente executar c√≥digo Python diretamente na sua resposta."

TOOL_DECLARATIONS = [
    {
        "functionDeclarations": [
            {
                "name": "consulta_tool",
                "description": "Realiza consultas e an√°lises estat√≠sticas no DataFrame (nomeado 'df'). Deve gerar o c√≥digo Python COMPLETO em string (ex: 'df.describe()', 'df[df[\"Class\"] == 1].shape[0]', 'df[\"Amount\"].mean()').",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {"codigo_python": {"type": "STRING", "description": "O c√≥digo Python v√°lido (como string) para executar no DataFrame 'df'."}},
                    "required": ["codigo_python"]
                }
            },
            {
                "name": "grafico_tool",
                "description": "Gera um gr√°fico com base nos dados. Tipos aceitos: 'hist' (1 coluna), 'box' (1 coluna, comparado com Class), 'scatter' (2 colunas), 'bar' (coluna 'Class').",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "tipo_grafico": {"type": "STRING", "description": "O tipo de gr√°fico a ser gerado ('hist', 'box', 'scatter', 'bar')."},
                        "colunas": {"type": "ARRAY", "description": "Uma lista de 1 ou 2 strings com os nomes das colunas.", "items": {"type": "STRING"}},
                        "titulo": {"type": "STRING", "description": "O t√≠tulo descritivo do gr√°fico."}
                    },
                    "required": ["tipo_grafico", "colunas", "titulo"]
                }
            }
        ]
    }
]

# Mapeamento para chamar as fun√ß√µes Python reais
# NOTA: O mapeamento √© feito dentro de run_conversation para passar o 'df'
# TOOL_MAP = { "consulta_tool": consulta_tool, "grafico_tool": grafico_tool }


# --- 2. Fun√ß√µes de Chamada de API e L√≥gica de Tool Calling ---

@st.cache_data(show_spinner=False)
def get_dataframe():
    """Carrega o DataFrame apenas uma vez e usa o cache do Streamlit."""
    return carregar_dados_ou_demo()

def make_api_call_with_backoff(payload, api_key, max_retries=5):
    """Realiza a chamada √† API do Gemini com backoff exponencial."""
    if not api_key: return None
    headers = {'Content-Type': 'application/json'}
    
    for attempt in range(max_retries):
        try:
            url_with_key = f"{API_URL}?key={api_key}"
            response = requests.post(url_with_key, headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            return response.json()
        except requests.exceptions.HTTPError as e:
            if response.status_code in [429, 500, 503] and attempt < max_retries - 1:
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                st.error(f"Erro HTTP {response.status_code}: {e}. Verifique a chave.")
                return None
        except requests.exceptions.RequestException as e:
            st.error(f"Erro de Conex√£o: {e}")
            return None
    
    st.error("N√∫mero m√°ximo de tentativas de API excedido.")
    return None

def run_conversation(df: pd.DataFrame, user_input: str, api_key: str):
    """Controla o fluxo da conversa (Usu√°rio -> Agente -> Ferramenta -> Agente)."""

    st.session_state.messages.append({"role": "user", "parts": [{"text": user_input}]})
    
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        placeholder.markdown("Pensando...")

        # --- Primeira Chamada: Agente decide ---
        payload = {
            "contents": st.session_state.messages,
            "tools": TOOL_DECLARATIONS,
            "systemInstruction": {"parts": [{"text": SYSTEM_INSTRUCTION_TEXT}]}
        }
        response_json = make_api_call_with_backoff(payload, api_key)
        if response_json is None: 
            st.session_state.messages.pop() # Remove entrada do usu√°rio
            return

        candidate = response_json.get("candidates", [{}])[0]
        first_part = candidate.get('content', {}).get('parts', [{}])[0]
        
        # --- L√≥gica de Chamada de Ferramenta ---
        if 'functionCall' in first_part or 'functionCalls' in first_part:
            
            function_calls = []
            if 'functionCalls' in first_part: function_calls = first_part['functionCalls']
            elif 'functionCall' in first_part: function_calls = [first_part['functionCall']]

            tool_results = []
            
            for call in function_calls:
                function_name = call['name']
                args = dict(call['args'])
                
                placeholder.markdown(f"**Agente executando:** `{function_name}`...")

                if function_name == "consulta_tool":
                    # Passa o df para a tool
                    result = consulta_tool(df, **args)
                    tool_response_text = result
                elif function_name == "grafico_tool":
                    # Passa o df para a tool
                    plot_buffer_or_error = grafico_tool(df, **args)
                    
                    if isinstance(plot_buffer_or_error, BytesIO):
                        # Armazena o buffer do gr√°fico na sess√£o para exibi√ß√£o
                        st.session_state.current_plot_buffer = plot_buffer_or_error
                        tool_response_text = f"Resultado: Gr√°fico gerado em mem√≥ria (BytesIO) com o t√≠tulo: {args.get('titulo')}"
                    else:
                        tool_response_text = f"Resultado: ERRO na gera√ß√£o do gr√°fico: {plot_buffer_or_error}"
                        
                else:
                    tool_response_text = f"ERRO: Fun√ß√£o '{function_name}' n√£o mapeada."

                tool_results.append({
                    "functionResponse": {
                        "name": function_name,
                        "response": {"result": tool_response_text}
                    }
                })

            # Adiciona o resultado da ferramenta ao hist√≥rico
            st.session_state.messages.append({"role": "tool", "parts": tool_results})
            
            # --- Segunda Chamada: Agente gera a resposta final ---
            payload_tool_response = {
                "contents": st.session_state.messages,
                "tools": TOOL_DECLARATIONS,
                "systemInstruction": {"parts": [{"text": SYSTEM_INSTRUCTION_TEXT}]}
            }
            
            final_response_json = make_api_call_with_backoff(payload_tool_response, api_key)
            
            if final_response_json is None: 
                st.session_state.messages.pop() # Remove tool
                st.session_state.messages.pop() # Remove user
                return
                
            final_text = final_response_json.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'N√£o foi poss√≠vel obter a resposta final do Agente.')
            
            placeholder.markdown(final_text)

            # Exibe o gr√°fico se ele foi gerado na primeira itera√ß√£o (grafico_tool)
            if 'current_plot_buffer' in st.session_state and st.session_state.current_plot_buffer is not None:
                st.image(st.session_state.current_plot_buffer, caption=args.get('titulo', 'Gr√°fico de An√°lise'), use_column_width=True)
                st.session_state.current_plot_buffer = None # Limpa ap√≥s exibi√ß√£o

            st.session_state.messages.append({"role": "model", "parts": [{"text": final_text}]})

        # --- L√≥gica de Resposta Direta (Sem Tool Call) ---
        else:
            agent_text = first_part.get('text', 'N√£o foi poss√≠vel obter resposta do Agente.')
            placeholder.markdown(agent_text)
            st.session_state.messages.append({"role": "model", "parts": [{"text": agent_text}]})


# --- 3. Streamlit UI (Interface do Usu√°rio) ---

st.set_page_config(page_title="Agente de An√°lise de Fraude Gemini", layout="centered")
st.title("Agente de An√°lise de Fraude üí≥")

# --- Carregamento e Gerenciamento do DataFrame ---
df_analysis = get_dataframe()

# --- Sidebar para a Chave API ---
with st.sidebar:
    st.header("Configura√ß√£o e Dados")
    # Tenta ler a chave de 'secrets' (Streamlit Cloud) ou usa string vazia
    api_key = st.text_input(
        "Sua Chave API do Gemini", 
        type="password",
        value=st.secrets.get("GEMINI_API_KEY", "")
    )
    if not api_key:
        st.warning("Insira a chave API para ativar o Agente.")

    st.markdown("---")
    
    st.subheader("Status do DataFrame")
    if df_analysis is not None:
        if df_analysis.shape[0] == 100:
            st.warning("Arquivo CSV **n√£o encontrado**. Usando dados de **DEMONSTRA√á√ÉO**.")
        else:
            st.success("Dados carregados com sucesso.")
        st.caption(f"Linhas: {df_analysis.shape[0]}, Colunas: {df_analysis.shape[1]}")
        st.dataframe(df_analysis.head(5), use_container_width=True)
    else:
        st.error("Falha ao carregar dados. Verifique a pasta 'data/'.")
    st.markdown("---")
    st.info("No Streamlit Cloud, configure o segredo `GEMINI_API_KEY`.")


# Inicializa o estado da sess√£o para o hist√≥rico do chat
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "model", "parts": [{"text": "Ol√°! Eu sou o Agente de An√°lise de Fraude. Fa√ßa uma pergunta sobre as transa√ß√µes, como **'Qual √© a m√©dia dos valores?'** ou **'Mostre um boxplot da V1.'**"}]}]
if "current_plot_buffer" not in st.session_state:
     st.session_state.current_plot_buffer = None


# --- Renderiza Hist√≥rico de Chat ---
for message in st.session_state.messages:
    if message["role"] in ["user", "model"]:
        with st.chat_message(message["role"]):
            st.markdown(message["parts"][0]["text"])
            
            # Reexibe o √∫ltimo gr√°fico se ele estiver no hist√≥rico (ap√≥s uma resposta do modelo)
            if message["role"] == "model" and st.session_state.current_plot_buffer is None:
                # Aqui voc√™ poderia adicionar l√≥gica para re-exibir gr√°ficos se necess√°rio,
                # mas mantemos a exibi√ß√£o simples ap√≥s a gera√ß√£o.
                pass 


# --- Caixa de Input do Usu√°rio ---
if df_analysis is not None:
    if prompt := st.chat_input("Pergunte sobre os dados de fraude..."):
        if not api_key:
            st.error("Por favor, insira sua Chave API do Gemini na barra lateral para come√ßar.")
        else:
            run_conversation(df_analysis, prompt, api_key)
